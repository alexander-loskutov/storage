# Usage

To use the app one will need to have Go and Docker installed.

### Run Postgres docker container

The app uses PostgreSQL as a database. Docker container will allow to quickly setup the RDBMS and use it for demo purposes.

```
docker run --name postgresqldb -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=admin -p 54321:5432 -v /data:/var/lib/postgresql/data -d postgres
```

### Clone this repo

```
$ git clone git@github.com:alexander-loskutov/storage.git
```

### Build application

As I used Windows during development and did not have chance to test it on other operating systems, all examples will be related to Windows.
In the repo root folder:

```
$ cd src
$ go build -o ../
```

This will create `storage.exe` in the root folder.

### Run application

In the repo root folder:

```
$ ./storage.exe
```

Default configuration file is located in the `cfg` folder and should work fine.
By default, the application will create a folder named  `in` next to itself and start watching it for incoming files.
Input directory can be changed via configuration file.

To write data to the storage, place a csv file with promotion records in the `in` folder created after application startup.

### Configuration

Configuration file location can be passed as a command line argument:

```
$ ./storage.exe --config=/path/to/config.yaml
```

#### Configuration file format

Configuration file must have `.yaml` format and must contain the following properties: 
* mode - SIMPLE or IMMUTABLE.
	* In the SIMPLE mode, data from new files are added to the existing storage
	* In the IMMUTABLE mode, the whole storage is erased and filled with the new data
* api
	* port - the port number on which REST API is available
* database
	* host - database host
	* port - database port
	* maintenance_db_name - name of administration database
	* app_db_name - name of the application database
* input_dir - the directory that is being watched for incoming files

#### Database credentials

Database user and password are passed via environment variables `DB_USER` and `DB_PASSWORD`. Default values are `postgres` and `admin` respectively.

### REST API

Default API port is 1321. It can be changed via configuration file. 
The API provides the following endpoint:

```
http://localhost:1321/promotions/:id
```

Since the example in the task is not completely clear (the URL contains an integer number, although the records do not contain any integer fields and `id` is UUID), this endpoint can handle both integers and UUIDs. Integer indices are autogenerated in sequence during upload.

### Answers to additional questions

Q: The .csv file could be very big (billions of entries) - how would your application perform?

A: I would suggest that we process the file in parallel goroutines so that each goroutine processes its own chunk (N bytes starting from byte M) and pass records to the consuming channel. On the next level, we could deploy several workers on several nodes and use the same approach. "Dispatcher" and "workers" can communicate via a message broker. The main problem with such huge files will be the database - 1 billion entries every 30 minutes means 500k insert operations per second which as for me sounds too much for an SQL database.

Q: How would your application perform in peak periods (millions of requests per minute)?

A: We could introduce a cache on the PromotionsService level. Since each record is of very small size, even in the case with billions of records a significant portion of them could fit in memory. Besides, PromotionsService can be extracted into a separate deployment and operated in a distributed manner. So that we would have the cache on each node and a load balancer could distribute requests evenly among them.

Q: How would you operate this app in production (e.g. deployment, scaling, monitoring)?

A: I don't have enough experience in DevOps. From what I know, tools like Kubernets are able to take care of deployment, scaling and monitoring.
